# ü§ñ Scraping Automatique PriceScan

Ce document explique le fonctionnement du syst√®me de scraping automatique int√©gr√© dans l'API PriceScan.

## üöÄ Fonctionnalit√©s

- **Scraping automatique** au d√©marrage de l'API
- **Intervalles configurables** : 5 jours en production, 1-2 heures en d√©veloppement
- **Support de 5 magasins** : Carrefour, Abidjan Mall, Prosuma, Playce, Jumia
- **Sauvegarde automatique** en base de donn√©es PostgreSQL
- **Gestion des erreurs** et retry automatique
- **Logs d√©taill√©s** pour le monitoring

## üè™ Magasins Support√©s

| Magasin | URL | Intervalle Production | Intervalle Dev |
|---------|-----|----------------------|----------------|
| Carrefour | carrefour.ci | 5 jours | 1 heure |
| Abidjan Mall | abidjanmall.org | 5 jours | 1 heure |
| Prosuma | groupeprosuma.com | 5 jours | 2 heures |
| Playce | playce.ci | 5 jours | 2 heures |
| Jumia | jumia.ci | 5 jours | 1 heure |

## ‚öôÔ∏è Configuration

### Variables d'Environnement

```bash
# Mode d'environnement
ENVIRONMENT=production  # ou development

# Activation du scraping
SCRAPING_ENABLED=true

# Intervalles (en secondes)
SCRAPING_CARREFOUR_INTERVAL=432000      # 5 jours
SCRAPING_ABIDJANMALL_INTERVAL=432000    # 5 jours
SCRAPING_PROSUMA_INTERVAL=432000        # 5 jours
SCRAPING_PLACE_INTERVAL=432000          # 5 jours
SCRAPING_JUMIA_INTERVAL=432000          # 5 jours
```

### Fichiers de Configuration

- `config/scraping_config.py` - Configuration principale
- `config/production.env` - Variables d'environnement production

## üöÄ Lancement

### Mode D√©veloppement

```bash
# Lancer l'API avec scraping automatique (1-2 heures)
python app.py
```

### Mode Production

```bash
# Lancer l'API avec scraping automatique (5 jours)
python run_production.py

# Ou avec variables d'environnement
ENVIRONMENT=production python app.py
```

## üß™ Tests

### Test Simple

```bash
# Test rapide du scraping
python test_simple_scraping.py
```

### Test Complet

```bash
# Test complet avec base de donn√©es
python test_auto_scraping.py
```

## üìä Monitoring

### Logs

Les logs sont sauvegard√©s dans :
- `logger/auto_scraper.log` - Logs du scraping automatique
- `logger/app.log` - Logs de l'application

### Statut en Temps R√©el

L'API expose des endpoints pour v√©rifier le statut :

```bash
# V√©rifier le statut du scraping
curl http://localhost:5000/api/scraping/status

# V√©rifier l'historique
curl http://localhost:5000/api/scraping/history
```

## üîß D√©pannage

### Probl√®mes Courants

1. **Scraping ne d√©marre pas**
   - V√©rifier `SCRAPING_ENABLED=true`
   - V√©rifier les logs dans `logger/auto_scraper.log`

2. **Erreurs de connexion**
   - V√©rifier la connectivit√© internet
   - V√©rifier les timeouts dans la configuration

3. **Base de donn√©es inaccessible**
   - V√©rifier la connexion PostgreSQL
   - V√©rifier les permissions utilisateur

### Logs de Debug

Pour activer les logs de debug :

```bash
SCRAPING_DEBUG=true python app.py
```

## üìà Performance

### Optimisations

- **Scraping parall√®le** : 4 workers simultan√©s
- **Cache des donn√©es** : √âvite les requ√™tes r√©p√©t√©es
- **Gestion des erreurs** : Continue en cas d'√©chec partiel
- **√âvitement des heures de pointe** : 9h-18h

### M√©triques

- **Taux de succ√®s** : Objectif > 80%
- **Temps de r√©ponse** : < 30 secondes par magasin
- **Utilisation m√©moire** : < 500MB
- **Utilisation CPU** : < 30% en moyenne

## üîí S√©curit√©

### Bonnes Pratiques

- **User-Agent rotation** pour √©viter la d√©tection
- **D√©lais al√©atoires** entre requ√™tes
- **Limitation du nombre de requ√™tes** par session
- **Respect des robots.txt** des sites cibles

### Configuration S√©curis√©e

```python
# Headers HTTP s√©curis√©s
HTTP_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9...',
    'Accept-Language': 'fr-FR,fr;q=0.8,en-US;q=0.5,en;q=0.3'
}
```

## üìù Contribution

### Ajouter un Nouveau Magasin

1. Cr√©er le module de scraping dans `helpers/scrapper/`
2. Ajouter la configuration dans `config/scraping_config.py`
3. Int√©grer dans `helpers/auto_scraper.py`
4. Tester avec `test_simple_scraping.py`

### Structure d'un Module de Scraping

```python
def scrape_magasin(query):
    """
    Scrape un magasin pour une requ√™te donn√©e
    
    Args:
        query (str): Terme de recherche
        
    Returns:
        list: Liste des produits trouv√©s
    """
    # Impl√©mentation du scraping
    pass
```

## üìû Support

Pour toute question ou probl√®me :

1. V√©rifier les logs dans `logger/auto_scraper.log`
2. Ex√©cuter `test_simple_scraping.py` pour diagnostiquer
3. V√©rifier la configuration dans `config/scraping_config.py`
4. Consulter la documentation des modules de scraping

---

**Note** : Ce syst√®me est con√ßu pour fonctionner de mani√®re autonome. Une fois configur√©, il s'ex√©cute automatiquement selon les intervalles d√©finis.
